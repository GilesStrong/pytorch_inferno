{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inferno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERNO loss\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_inferno.model_wrapper import ModelWrapper\n",
    "from pytorch_inferno.callback import *\n",
    "from pytorch_inferno.data import get_paper_data\n",
    "from pytorch_inferno.plotting import *\n",
    "from pytorch_inferno.inference import *\n",
    "from pytorch_inferno.utils import *\n",
    "\n",
    "from fastcore.all import partialler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from typing import *\n",
    "from collections import OrderedDict\n",
    "from fastcore.all import store_attr\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 200\n",
    "data, test = get_paper_data(200000, bm=0, bs=bs, n_test=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class VariableSoftmax(nn.Softmax):\n",
    "    def __init__(self, temp:float=1, dim:int=-1):\n",
    "        super().__init__(dim=dim)\n",
    "        self.temp = temp\n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor: return super().forward(x/self.temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.0492e-08, 9.9981e-01, 1.8703e-10, 1.8962e-15, 3.3516e-14, 1.8583e-04,\n",
       "          1.3037e-16, 1.8234e-10, 9.0611e-06, 5.0900e-15]]),\n",
       " tensor([[2.1731e-02, 7.4947e-01, 8.4948e-03, 8.5182e-04, 1.5129e-03, 1.3446e-01,\n",
       "          4.9866e-04, 8.4518e-03, 7.3487e-02, 1.0378e-03]]),\n",
       " tensor([[0.0753, 0.4422, 0.0471, 0.0149, 0.0199, 0.1873, 0.0114, 0.0470, 0.1385,\n",
       "          0.0165]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VariableSoftmax(0.1)(x), VariableSoftmax(0.5)(x), VariableSoftmax(1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(3,100),  nn.ReLU(),\n",
    "                    nn.Linear(100,100),nn.ReLU(),\n",
    "                    nn.Linear(100,10), VariableSoftmax(0.1))\n",
    "init_net(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w = next(iter(data.trn_dl))\n",
    "preds = net(x)\n",
    "assert preds.shape == (bs,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
