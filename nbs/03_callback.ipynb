{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback\n",
    "\n",
    "Collection of callbacks for use during training and prediction to augment the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from pytorch_inferno.utils import to_np\n",
    "\n",
    "from typing import Optional, Callable, Union\n",
    "from abc import ABC\n",
    "from fastcore.all import store_attr, Path\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AbsCallback(ABC):\n",
    "    r'''Abstract callback passing though all action points and indicating where callbacks can affect the model.\n",
    "    See `ModelWrapper` etc. to see where exactly these action points are called.'''\n",
    "    def __init__(self): pass\n",
    "    def set_wrapper(self, wrapper) -> None: self.wrapper = wrapper  \n",
    "    def on_train_begin(self) -> None: pass\n",
    "    def on_train_end(self) -> None: pass \n",
    "    \n",
    "    def on_epoch_begin(self) -> None: pass\n",
    "    def on_epoch_end(self) -> None:   pass\n",
    "    \n",
    "    def on_batch_begin(self) -> None: pass\n",
    "    def on_batch_end(self) -> None:   pass\n",
    "    \n",
    "    def on_forwards_end(self) -> None: pass\n",
    "    \n",
    "    def on_backwards_begin(self) -> None: pass\n",
    "    def on_backwards_end(self) -> None:   pass\n",
    "        \n",
    "    def on_pred_begin(self) -> None: pass\n",
    "    def on_pred_end(self) -> None:   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LossTracker(AbsCallback):\n",
    "    r'''Tracks training and validation losses during training.\n",
    "    Losses are assumed to be averaged and will be re-averaged over the epoch unless `loss_is_meaned` is false.'''\n",
    "    def __init__(self, loss_is_meaned:bool=True):\n",
    "        store_attr()\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self) -> None: self.losses,self.epoch = {'trn':[], 'val':[]},0\n",
    "    def on_train_begin(self) -> None: self.reset()\n",
    "    def on_epoch_begin(self) -> None: self.loss,self.cnt = 0,0\n",
    "        \n",
    "    def on_epoch_end(self) -> None:\n",
    "        if self.wrapper.state == 'train':\n",
    "            self.losses['trn'].append(self.loss/self.cnt)\n",
    "        else:\n",
    "            self.losses['val'].append(self.loss/self.cnt)\n",
    "            self.epoch += 1\n",
    "            print(f'{self.epoch}: Train={self.losses[\"trn\"][-1]} Valid={self.losses[\"val\"][-1]}')\n",
    "            \n",
    "    def on_forwards_end(self) -> None:\n",
    "        sz = len(self.wrapper.x) if self.loss_is_meaned else 1\n",
    "        self.loss += self.wrapper.loss_val.data.item()*sz\n",
    "        self.cnt += sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EarlyStopping(AbsCallback):\n",
    "    r'''Tracks validation loss during training and terminates training if loss doesn't decrease after `patience` number of epochs.\n",
    "    Losses are assumed to be averaged and will be re-averaged over the epoch unless `loss_is_meaned` is false.'''\n",
    "    def __init__(self, patience:int, loss_is_meaned:bool=True):\n",
    "        store_attr()\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self) -> None: self.epochs,self.min_loss = 0,math.inf\n",
    "    def on_train_begin(self) -> None: self.reset()\n",
    "    def on_epoch_begin(self) -> None: self.loss,self.cnt = 0,0\n",
    "        \n",
    "    def on_forwards_end(self) -> None:\n",
    "        if self.wrapper.state == 'valid':\n",
    "            sz = len(self.wrapper.x) if self.loss_is_meaned else 1\n",
    "            self.loss += self.wrapper.loss_val.data.item()*sz\n",
    "            self.cnt += sz\n",
    "        \n",
    "    def on_epoch_end(self) -> None:\n",
    "        if self.wrapper.state == 'valid':\n",
    "            loss = self.loss/self.cnt\n",
    "            if loss < self.min_loss:\n",
    "                self.min_loss = loss\n",
    "                self.epochs = 0\n",
    "            else:\n",
    "                self.epochs += 1\n",
    "            if self.epochs >= self.patience:\n",
    "                print('Early stopping')\n",
    "                self.wrapper.stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SaveBest(AbsCallback):\n",
    "    r'''Tracks validation loss during training and automatically saves a copy of the weights to indicated file whenever validation loss decreases.\n",
    "    Losses are assumed to be averaged and will be re-averaged over the epoch unless `loss_is_meaned` is false.'''\n",
    "    def __init__(self, savename:Union[str,Path], auto_reload:bool=True, loss_is_meaned:bool=True):\n",
    "        savename = Path(savename)\n",
    "        store_attr()\n",
    "        self.reset()\n",
    "        \n",
    "    def on_train_begin(self) -> None: self.reset()\n",
    "    def on_epoch_begin(self) -> None: self.loss,self.cnt = 0,0\n",
    "        \n",
    "    def reset(self) -> None:\n",
    "        self.min_loss = math.inf\n",
    "        self.savename.parent.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "    def on_forwards_end(self) -> None:\n",
    "        if self.wrapper.state == 'valid':\n",
    "            sz = len(self.wrapper.x) if self.loss_is_meaned else 1\n",
    "            self.loss += self.wrapper.loss_val.data.item()*sz\n",
    "            self.cnt += sz\n",
    "        \n",
    "    def on_epoch_end(self) -> None:\n",
    "        if self.wrapper.state == 'valid':\n",
    "            loss = self.loss/self.cnt\n",
    "            if loss < self.min_loss:\n",
    "                self.min_loss = loss\n",
    "                self.wrapper.save(self.savename)\n",
    "                \n",
    "    def on_train_end(self) -> None:\n",
    "        print(f'Loading best model with loss {self.min_loss}')\n",
    "        self.wrapper.load(self.savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PredHandler(AbsCallback):\n",
    "    r'''Default callback for predictions. Collects predictions over batches and returns them as stacked array'''\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self) -> None: self.preds = []\n",
    "    def on_pred_begin(self) -> None: self.reset()\n",
    "    def on_pred_end(self) -> None: self.preds = np.vstack(self.preds)\n",
    "    def get_preds(self) -> np.ndarray: return self.preds        \n",
    "    def on_forwards_end(self) -> None:\n",
    "        if self.wrapper.state == 'test': self.preds.append(to_np(self.wrapper.y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PaperSystMod(AbsCallback):\n",
    "    r'''Prediction callback for modifying input data from INFERNO paper according to specified nuisances.'''\n",
    "    def __init__(self, r:float=0, l:float=3): store_attr()\n",
    "    def on_batch_begin(self) -> None:\n",
    "        self.wrapper.x[:,0] += self.r\n",
    "        self.wrapper.x[:,2] *= self.l/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GradClip(AbsCallback):\n",
    "    r'''Training callback implementing gradient clipping'''\n",
    "    def __init__(self, clip:float, clip_norm:bool=True):\n",
    "        self.clip = clip\n",
    "        self.func = nn.utils.clip_grad_norm_ if clip_norm else nn.utils.clip_grad_value_\n",
    "        \n",
    "    def on_backwards_end(self) -> None:\n",
    "        if self.clip > 0: self.func(self.wrapper.model.parameters(), self.clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
