---

title: Inference


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/06_inference.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/06_inference.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">reload_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

</div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bin_preds" class="doc_header"><code>bin_preds</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L25" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>bin_preds</code>()</p>
</blockquote>
<p>Bins predictions over specified range</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_shape" class="doc_header"><code>get_shape</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L30" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_shape</code>()</p>
</blockquote>
<p>Extracts normalised shape of class from binned predictions. Empty bins are filled with a small quantity to avoid zeros.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_paper_syst_shapes" class="doc_header"><code>get_paper_syst_shapes</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L39" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_paper_syst_shapes</code>()</p>
</blockquote>
<p>Pass background data through trained model in order to get up/down shape variations.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_likelihood_width" class="doc_header"><code>get_likelihood_width</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L62" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_likelihood_width</code>(<strong><code>nll</code></strong>:<code>ndarray</code>, <strong><code>mu_scan</code></strong>:<code>ndarray</code>, <strong><code>val</code></strong>:<code>float</code>=<em><code>0.5</code></em>)</p>
</blockquote>
<p>Compute width of likelihood at 95% confidence-level</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="interp_shape" class="doc_header"><code>interp_shape</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L69" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>interp_shape</code>(<strong><code>alpha</code></strong>:<code>Tensor</code>, <strong><code>f_b_nom</code></strong>:<code>Tensor</code>, <strong><code>f_b_up</code></strong>:<code>Tensor</code>, <strong><code>f_b_dw</code></strong>:<code>Tensor</code>)</p>
</blockquote>
<p>Use quadratic interpolation between up/down systematic shapes and nominal in order to estimate shapes at arbitrary nuisance values.
Linear extrapolation for absolute nuisances values greater than 1 (outside up/down shape range).
Does not account for co-dependence of nuisances.
Adapted from <a href="https://github.com/pablodecm/paper-inferno/blob/master/code/template_model.py">https://github.com/pablodecm/paper-inferno/blob/master/code/template_model.py</a> under BSD 3-clause licence Copyright (c) 2018, Pablo de Castro, Tommaso Dorigo</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">parallel_calc_nll</span><span class="p">(</span><span class="n">s_true</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">b_true</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">s_exp</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">f_s</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span>
             <span class="n">f_b_nom</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">f_b_up</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">f_b_dw</span><span class="p">:</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&#39;&#39;&#39;Unused</span>
<span class="sd">    Compute multiple negative log-likelihood for specified parameters. Unused due to difficulty of batch-wise hessians in PyTorch.&#39;&#39;&#39;</span>
    <span class="n">f_b</span> <span class="o">=</span> <span class="n">interp_shape</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">f_b_nom</span><span class="p">,</span> <span class="n">f_b_up</span><span class="p">,</span> <span class="n">f_b_dw</span><span class="p">)</span>
    <span class="n">t_exp</span> <span class="o">=</span> <span class="p">(</span><span class="n">s_exp</span><span class="p">[:,</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">f_s</span><span class="p">[</span><span class="kc">None</span><span class="p">,])</span><span class="o">+</span><span class="p">(</span><span class="n">b_true</span><span class="o">*</span><span class="n">f_b</span><span class="p">)</span>
    <span class="n">asimov</span> <span class="o">=</span> <span class="p">(</span><span class="n">s_true</span><span class="o">*</span><span class="n">f_s</span><span class="p">)</span><span class="o">+</span><span class="p">(</span><span class="n">b_true</span><span class="o">*</span><span class="n">f_b_nom</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="n">t_exp</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">asimov</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">calc_diag_grad_hesse</span><span class="p">(</span><span class="n">nll</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="sa">r</span><span class="sd">&#39;&#39;&#39;Unused</span>
<span class="sd">    Compute batch-wise gradient and hessian, but only the diagonal elements.&#39;&#39;&#39;</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">nll</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">nll</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">nll</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">hesse</span> <span class="o">=</span> <span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">nll</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">alpha</span><span class="o">.</span><span class="n">grad</span><span class="o">=</span><span class="kc">None</span>
    <span class="k">return</span> <span class="n">grad</span><span class="p">,</span> <span class="n">hesse</span>
</pre></div>

</div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">calc_diag_profile</span><span class="p">(</span><span class="n">f_s</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">f_b_nom</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">f_b_up</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">f_b_dw</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>
                      <span class="n">mu_scan</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">true_mu</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="n">verbose</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&#39;&#39;&#39;Unused</span>
<span class="sd">    Compute profile likelihood for range of mu values, but only optimise using diagonal hessian elements.&#39;&#39;&#39;</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">mu_scan</span><span class="p">),</span><span class="n">f_b_up</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">f_b_nom</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">f_b_nom</span> <span class="o">=</span> <span class="n">f_b_nom</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">get_nll</span> <span class="o">=</span> <span class="n">partialler</span><span class="p">(</span><span class="n">parallel_calc_nll</span><span class="p">,</span> <span class="n">s_true</span><span class="o">=</span><span class="n">true_mu</span><span class="p">,</span> <span class="n">b_true</span><span class="o">=</span><span class="n">n</span><span class="o">-</span><span class="n">true_mu</span><span class="p">,</span> <span class="n">s_exp</span><span class="o">=</span><span class="n">mu_scan</span><span class="p">,</span>
                         <span class="n">f_s</span><span class="o">=</span><span class="n">f_s</span><span class="p">,</span> <span class="n">f_b_nom</span><span class="o">=</span><span class="n">f_b_nom</span><span class="p">,</span> <span class="n">f_b_up</span><span class="o">=</span><span class="n">f_b_up</span><span class="p">,</span> <span class="n">f_b_dw</span><span class="o">=</span><span class="n">f_b_dw</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>  <span class="c1"># Newton optimise nuisances</span>
        <span class="n">nll</span> <span class="o">=</span> <span class="n">get_nll</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">grad</span><span class="p">,</span> <span class="n">hesse</span> <span class="o">=</span> <span class="n">calc_diag_grad_hesse</span><span class="p">(</span><span class="n">nll</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="n">step</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">lr</span><span class="o">*</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="n">hesse</span><span class="o">+</span><span class="mf">1e-7</span><span class="p">),</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">-</span><span class="n">step</span>
    <span class="k">return</span> <span class="n">get_nll</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">),</span> <span class="n">alpha</span>
</pre></div>

</div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="calc_nll" class="doc_header"><code>calc_nll</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L85" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>calc_nll</code>(<strong><code>s_true</code></strong>:<code>float</code>, <strong><code>b_true</code></strong>:<code>float</code>, <strong><code>s_exp</code></strong>:<code>float</code>, <strong><code>f_s</code></strong>:<code>Tensor</code>, <strong><code>alpha</code></strong>:<code>Tensor</code>, <strong><code>f_b_nom</code></strong>:<code>Tensor</code>, <strong><code>f_b_up</code></strong>:<code>Optional</code>[<code>Tensor</code>], <strong><code>f_b_dw</code></strong>:<code>Optional</code>[<code>Tensor</code>])</p>
</blockquote>
<p>Compute negative log-likelihood for specified parameters.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="jacobian" class="doc_header"><code>jacobian</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L95" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>jacobian</code>(<strong><code>y</code></strong>:<code>Tensor</code>, <strong><code>x</code></strong>:<code>Tensor</code>, <strong><code>create_graph</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Compute full jacobian matrix for single tensor. Call twice for hessian.
Copied from <a href="https://gist.github.com/apaszke/226abdf867c4e9d6698bd198f3b45fb7">https://gist.github.com/apaszke/226abdf867c4e9d6698bd198f3b45fb7</a> credits: Adam Paszke
TODO: Fix this to work batch-wise (maybe <a href="https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa">https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa</a>)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="calc_grad_hesse" class="doc_header"><code>calc_grad_hesse</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L110" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>calc_grad_hesse</code>(<strong><code>nll</code></strong>:<code>Tensor</code>, <strong><code>alpha</code></strong>:<code>Tensor</code>, <strong><code>create_graph</code></strong>:<code>bool</code>=<em><code>False</code></em>)</p>
</blockquote>
<p>Compute full hessian and jacobian for single tensor</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="calc_profile" class="doc_header"><code>calc_profile</code><a href="https://github.com/GilesStrong/pytorch_inferno/tree/master/pytorch_inferno/inference.py#L117" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>calc_profile</code>(<strong><code>f_s</code></strong>:<code>Tensor</code>, <strong><code>f_b_nom</code></strong>:<code>Tensor</code>, <strong><code>f_b_up</code></strong>:<code>Tensor</code>, <strong><code>f_b_dw</code></strong>:<code>Tensor</code>, <strong><code>n</code></strong>:<code>int</code>, <strong><code>mu_scan</code></strong>:<code>Tensor</code>, <strong><code>true_mu</code></strong>:<code>int</code>, <strong><code>n_steps</code></strong>:<code>int</code>=<em><code>100</code></em>, <strong><code>lr</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>verbose</code></strong>:<code>bool</code>=<em><code>True</code></em>)</p>
</blockquote>
<p>Compute profile likelihoods for range of mu values, optimising on full hessian.
Ideally mu-values should be computed in parallel, but batch-wise hessian in PyTorch is difficult.
TODO: Fix this to run mu-scan in parallel</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

